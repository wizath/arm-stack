#!/usr/bin/env python3
"""
ARM Stack Usage Analyzer

A comprehensive tool for analyzing stack usage in ARM embedded projects.
This tool parses object files and stack usage information to provide detailed
analysis of function call graphs and stack consumption patterns.

Originally inspired by avstack.pl, this implementation provides enhanced
visualization, filtering capabilities, and better error handling.

Requirements:
    - ARM GCC toolchain (arm-none-eabi-objdump)
    - Project compiled with -fstack-usage flag
    - Object files (.o) and stack usage files (.su)

Author: wizath
GitHub: https://github.com/wizath
License: MIT
Version: 1.0
"""

import sys
import os
import re
import subprocess
import glob
from collections import defaultdict, namedtuple
from typing import Dict, Set, List, Optional, Tuple
import argparse
from pathlib import Path

# Version information
__version__ = "1.0"
__author__ = "wizath"
__github__ = "https://github.com/wizath"

class Colors:
    """ANSI color codes for enhanced terminal output"""
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'
    END = '\033[0m'

# Tool configuration constants
OBJDUMP = "arm-none-eabi-objdump"
CALL_COST = 4  # ARM function call overhead in bytes

# Data structure for function information
FunctionInfo = namedtuple('FunctionInfo', [
    'name',         # Function name (cleaned)
    'cost',         # Total stack cost including callees
    'frame_size',   # Local frame size from .su file
    'height',       # Call chain depth
    'is_recursive', # Whether function is recursive
    'is_root'       # Whether function is a root (entry point)
])

class StackAnalyzer:
    """
    Main analyzer class for processing ARM object files and calculating stack usage.
    
    This class implements the core algorithm for:
    - Parsing object file disassembly to build call graphs
    - Reading stack usage information from .su files
    - Resolving function symbols across object files
    - Calculating total stack costs through call graph traversal
    - Generating comprehensive analysis reports
    """
    
    def __init__(self, build_dir: str, threshold: int = 10, show_warnings: bool = True):
        """
        Initialize the stack analyzer.
        
        Args:
            build_dir: Path to build directory containing object files
            threshold: Minimum stack usage threshold for reporting (bytes)
            show_warnings: Whether to display symbol resolution warnings
        """
        self.build_dir = Path(build_dir)
        self.threshold = threshold
        self.show_warnings = show_warnings
        
        # Core data structures for analysis
        self.frame_size: Dict[str, int] = {}  # "func@file" -> frame size in bytes
        self.call_graph: Dict[str, Set[str]] = defaultdict(set)  # "func@file" -> {callees}
        self.total_cost: Dict[str, int] = {}  # "func@file" -> total stack cost
        self.call_depth: Dict[str, int] = {}  # "func@file" -> maximum call depth
        self.visited: Dict[str, str] = {}  # "func@file" -> traversal status
        self.has_caller: Set[str] = set()  # Functions called by others
        self.unresolved: Set[str] = set()  # Unresolved function references
        
        # Symbol resolution tables
        self.addresses: Dict[int, str] = {}  # address -> "func@file"
        self.global_name: Dict[str, str] = {}  # func_name -> "func@file"
        self.ambiguous: Set[str] = set()  # Functions with ambiguous names

    def find_object_files(self) -> List[str]:
        """
        Locate all relevant object files in the build directory.
        
        Filters out CMake compiler identification files and other non-project objects.
        
        Returns:
            List of object file paths
            
        Raises:
            FileNotFoundError: If build directory doesn't exist or no object files found
        """
        if not self.build_dir.exists():
            raise FileNotFoundError(f"Build directory '{self.build_dir}' does not exist")
        
        obj_files = []
        for pattern in ["**/*.o"]:
            all_files = glob.glob(str(self.build_dir / pattern), recursive=True)
            # Filter out CMake-generated compiler test files
            for file in all_files:
                if not any(exclude in file for exclude in [
                    'CompilerIdC', 'CompilerIdCXX', 'CMakeCCompilerId', 'CMakeCXXCompilerId'
                ]):
                    obj_files.append(file)
        
        if not obj_files:
            raise FileNotFoundError(f"No relevant object files (.o) found in '{self.build_dir}'")
        
        return sorted(obj_files)

    def check_prerequisites(self) -> None:
        """
        Verify that all required tools and files are available for analysis.
        
        Checks for:
        - ARM objdump tool availability
        - Build directory existence
        - Presence of object files and stack usage files
        
        Returns:
            List of object files to process
            
        Raises:
            SystemExit: If prerequisites are not met
        """
        print(f"{Colors.CYAN}🔍 Checking prerequisites...{Colors.END}")
        
        # Verify ARM toolchain availability
        try:
            subprocess.run([OBJDUMP, "--version"], capture_output=True, check=True)
            print(f"  ✓ {OBJDUMP} found")
        except (subprocess.CalledProcessError, FileNotFoundError):
            print(f"{Colors.RED}❌ Error: {OBJDUMP} not found. Please install ARM GCC toolchain.{Colors.END}")
            sys.exit(1)
        
        # Verify build directory
        if not self.build_dir.exists():
            print(f"{Colors.RED}❌ Error: Build directory '{self.build_dir}' does not exist.{Colors.END}")
            print(f"{Colors.YELLOW}💡 Please run cmake and build the project first.{Colors.END}")
            sys.exit(1)
        
        # Locate object files
        obj_files = self.find_object_files()
        print(f"  ✓ Found {len(obj_files)} object files")
        
        # Verify stack usage files exist
        su_files = []
        for obj_file in obj_files:
            su_file = obj_file[:-2] + '.su'
            if os.path.exists(su_file):
                su_files.append(su_file)
        
        if not su_files:
            print(f"{Colors.RED}❌ Error: No stack usage files (.su) found.{Colors.END}")
            print(f"{Colors.YELLOW}💡 Please compile with -fstack-usage flag to generate .su files.{Colors.END}")
            print(f"{Colors.YELLOW}💡 Add '-fstack-usage' to your CMakeLists.txt target_compile_options.{Colors.END}")
            sys.exit(1)
        
        print(f"  ✓ Found {len(su_files)} stack usage files (from {len(obj_files)} object files)")
        
        return obj_files

    def parse_object_files(self, obj_files: List[str]) -> None:
        """
        Parse all object files to extract call graph and stack usage information.
        
        For each object file:
        - Disassembles to find function calls and build call graph
        - Reads corresponding .su file for stack frame sizes
        
        Args:
            obj_files: List of object file paths to process
        """
        print(f"{Colors.CYAN}📁 Parsing {len(obj_files)} object files... ", end="", flush=True)
        
        for i, obj_file in enumerate(obj_files, 1):
            # Progress indicator for large projects
            if i % 10 == 0 or i == len(obj_files):
                print(f"{i}/{len(obj_files)}", end=" ", flush=True)
            
            self._parse_disassembly(obj_file)
            self._parse_su_file(obj_file)
        
        print(f"{Colors.GREEN}✓{Colors.END}")

    def _parse_disassembly(self, obj_file: str) -> None:
        """
        Parse objdump disassembly output to build function call graph.
        
        Extracts:
        - Function definitions and their addresses
        - Function call relationships via relocation entries
        - Symbol address mappings for resolution
        
        Args:
            obj_file: Path to object file to disassemble
            
        Raises:
            SystemExit: If disassembly fails
        """
        try:
            result = subprocess.run([OBJDUMP, "-dr", obj_file], 
                                  capture_output=True, text=True, check=True)
            
            current_function = None
            
            for line in result.stdout.splitlines():
                line = line.strip()
                
                # Match function definition: "00000000 <function_name>:"
                func_match = re.match(r'^([0-9a-fA-F]+) <(.*)>:', line)
                if func_match:
                    addr, name = func_match.groups()
                    current_function = f"{name}@{obj_file}"
                    self.call_graph[current_function] = set()
                    
                    # Track ambiguous function names across object files
                    if name in self.global_name:
                        self.ambiguous.add(name)
                    self.global_name[name] = current_function
                    
                    # Store address mapping for symbol resolution
                    addr = addr.lstrip('0') or '0'
                    self.addresses[f"{addr}@{obj_file}"] = current_function
                
                # Match function call: ": R_ARM_CALL target"
                call_match = re.search(r': R_[A-Za-z0-9_]+_CALL\s+(.+)', line)
                if call_match and current_function:
                    target = call_match.group(1)
                    
                    # Handle different call target formats
                    if target == ".text":
                        target = f"@{obj_file}"
                    elif target.startswith(".text+0x"):
                        offset = target[9:]  # Remove ".text+0x" prefix
                        target = f"{offset}@{obj_file}"
                    
                    self.call_graph[current_function].add(target)
                    
        except subprocess.CalledProcessError as e:
            print(f"{Colors.RED}❌ Error disassembling {obj_file}: {e}{Colors.END}")
            sys.exit(1)

    def _parse_su_file(self, obj_file: str) -> None:
        """
        Parse stack usage (.su) file to extract function frame sizes.
        
        The .su file format is: "path:line:column:function_name size qualifier"
        Frame sizes are adjusted by adding the ARM call overhead cost.
        
        Args:
            obj_file: Object file path (corresponding .su file will be located)
        """
        if not obj_file.endswith('.o'):
            return
            
        su_file = obj_file[:-2] + '.su'
        
        try:
            with open(su_file, 'r') as f:
                for line in f:
                    # Parse: "/path/file.c:137:20:function_name   size   qualifier"
                    match = re.search(r':([^:\t ]+)[\t ]+([0-9]+)[\t ]+', line)
                    if match:
                        func_name, size = match.groups()
                        # Add ARM function call overhead to frame size
                        self.frame_size[f"{func_name}@{obj_file}"] = int(size) + CALL_COST
                        
        except FileNotFoundError:
            # Stack usage files may not exist for assembly files or system libraries
            pass

    def resolve_symbols(self) -> None:
        """
        Resolve function call targets using symbol tables and address mappings.
        
        This process converts raw call targets (addresses, offsets, names) into
        fully qualified function references that can be used for call graph analysis.
        
        Resolution priority:
        1. Direct address matches
        2. Global symbol name matches
        3. Existing call graph entries
        4. Mark as unresolved
        """
        print(f"{Colors.CYAN}🔗 Resolving symbols...{Colors.END}")
        
        for func_name, callees in self.call_graph.items():
            resolved = set()
            
            for target in callees:
                if target in self.addresses:
                    # Direct address match
                    resolved.add(self.addresses[target])
                elif target in self.global_name:
                    # Global symbol name match
                    resolved.add(self.global_name[target])
                    if target in self.ambiguous and self.show_warnings:
                        print(f"{Colors.YELLOW}⚠️  Ambiguous resolution: {target}{Colors.END}")
                elif target in self.call_graph:
                    # Already in call graph
                    resolved.add(target)
                else:
                    # Cannot resolve - likely external library function
                    self.unresolved.add(target)
            
            self.call_graph[func_name] = resolved

    def create_interrupt_node(self) -> None:
        """
        Create virtual interrupt node for interrupt service routine analysis.
        
        This creates a synthetic "INTERRUPT" node that calls all interrupt handlers
        (functions matching "__vector_*" pattern). This allows calculation of
        worst-case interrupt stack usage.
        """
        self.call_graph["INTERRUPT"] = set()
        
        for func_name in self.call_graph:
            if "__vector_" in func_name:
                self.call_graph["INTERRUPT"].add(func_name)

    def trace_call_graph(self) -> None:
        """
        Traverse the call graph to calculate stack costs and call depths.
        
        Uses depth-first traversal with memoization to compute:
        - Total stack cost: frame size + maximum callee cost
        - Call depth: maximum depth of any call path
        - Recursion detection: marks recursive functions
        
        The algorithm handles cycles by detecting when a function is revisited
        during traversal and marking it as recursive.
        """
        print(f"{Colors.CYAN}📊 Analyzing call graph...{Colors.END}")
        
        def trace(func_name: str) -> None:
            """Recursive traversal function with cycle detection"""
            if func_name in self.visited:
                if self.visited[func_name] == "?":
                    # Cycle detected - mark as recursive
                    self.visited[func_name] = "R"
                return
            
            # Mark as currently being processed
            self.visited[func_name] = "?"
            
            max_depth = 0
            max_frame = 0
            
            # Process all callees
            if func_name in self.call_graph:
                for callee in self.call_graph[func_name]:
                    self.has_caller.add(callee)
                    trace(callee)
                    
                    callee_cost = self.total_cost.get(callee, 0)
                    callee_depth = self.call_depth.get(callee, 0)
                    
                    # Track maximum cost and depth among callees
                    max_frame = max(max_frame, callee_cost)
                    max_depth = max(max_depth, callee_depth)
            
            # Calculate final values
            self.call_depth[func_name] = max_depth + 1
            self.total_cost[func_name] = max_frame + self.frame_size.get(func_name, 0)
            
            # Mark as completed (if not recursive)
            if self.visited[func_name] == "?":
                self.visited[func_name] = " "
        
        # Process all functions in the call graph
        for func_name in self.call_graph:
            trace(func_name)

    def generate_report(self) -> None:
        """
        Generate and display comprehensive stack usage analysis report.
        
        The report includes:
        - File-based stack usage summary
        - Detailed function table with costs and depths
        - Peak stack usage estimates
        - Unresolved function warnings
        """
        print(f"\n{Colors.BOLD}{Colors.HEADER}{'='*80}{Colors.END}")
        print(f"{Colors.BOLD}{Colors.HEADER}📈 STACK USAGE ANALYSIS REPORT{Colors.END}")
        print(f"{Colors.BOLD}{Colors.HEADER}{'='*80}{Colors.END}\n")
        
        # Prepare function data and file statistics
        functions = []
        file_stats = defaultdict(lambda: {'count': 0, 'total_cost': 0, 'max_cost': 0, 'functions': []})
        max_iv_cost = 0
        main_cost = 0
        
        for func_full_name in sorted(self.total_cost.keys(), 
                                   key=lambda x: self.total_cost[x], reverse=True):
            
            # Extract clean function name and source file
            display_name = func_full_name
            source_file = "unknown"
            
            if '@' in func_full_name:
                base_name = func_full_name.split('@')[0]
                obj_file = func_full_name.split('@')[1]
                
                # Extract source file name from object file path
                if '/' in obj_file:
                    source_file = os.path.basename(obj_file).replace('.o', '')
                else:
                    source_file = obj_file.replace('.o', '')
                
                # Use clean name if not ambiguous
                if base_name not in self.ambiguous:
                    display_name = base_name
            
            # Determine function characteristics
            is_recursive = self.visited.get(func_full_name, ' ') == 'R'
            is_root = func_full_name not in self.has_caller
            cost = self.total_cost[func_full_name]
            
            # Track special functions for summary
            if "__vector_" in func_full_name:
                max_iv_cost = max(max_iv_cost, cost)
            elif func_full_name.startswith("main@"):
                main_cost = cost
            
            func_info = FunctionInfo(
                name=display_name,
                cost=cost,
                frame_size=self.frame_size.get(func_full_name, 0),
                height=self.call_depth.get(func_full_name, 0),
                is_recursive=is_recursive,
                is_root=is_root
            )
            
            functions.append(func_info)
            
            # Update file statistics
            if cost > 0:
                file_stats[source_file]['count'] += 1
                file_stats[source_file]['total_cost'] += cost
                file_stats[source_file]['max_cost'] = max(file_stats[source_file]['max_cost'], cost)
                file_stats[source_file]['functions'].append((display_name, cost, is_root))
        
        # Generate report sections
        self._print_file_hierarchy(file_stats)
        self._print_function_table(functions)
        self._print_summary(main_cost, max_iv_cost)
        self._print_unresolved()

    def _print_file_hierarchy(self, file_stats: Dict) -> None:
        """
        Display stack usage organized by source file.
        
        Shows top functions per file and total usage statistics.
        
        Args:
            file_stats: Dictionary mapping filenames to usage statistics
        """
        print(f"{Colors.BOLD}📁 Stack Usage by Source File{Colors.END}\n")
        
        # Sort files by total stack usage (descending)
        sorted_files = sorted(file_stats.items(), 
                            key=lambda x: x[1]['total_cost'], reverse=True)
        
        # Display files with non-zero stack usage
        for filename, stats in sorted_files:
            if stats['total_cost'] > 0:
                # Show top 3 functions per file
                top_funcs = sorted(stats['functions'], key=lambda x: x[1], reverse=True)[:3]
                
                print(f"{filename}")
                for name, cost, is_root in top_funcs:
                    print(f"  - {name} ({cost} bytes)")
                print(f"  Total: {stats['total_cost']} bytes ({stats['count']} functions)\n")

    def _print_function_table(self, functions: List[FunctionInfo]) -> None:
        """
        Display detailed function stack usage table.
        
        Shows functions above the threshold with their costs, frame sizes,
        and call depths. Functions are sorted by total cost (descending).
        
        Args:
            functions: List of function information objects
        """
        # Apply threshold filter
        filtered_functions = [f for f in functions if f.cost >= self.threshold]
        
        if not filtered_functions:
            print(f"{Colors.YELLOW}⚠️  No functions with significant stack usage found{Colors.END}")
            return
        
        print(f"{Colors.BOLD}📋 Function Stack Usage Analysis{Colors.END}")
        print(f"{Colors.CYAN}   (Showing {len(filtered_functions)} functions with stack usage ≥{self.threshold} bytes){Colors.END}")
        print(f"{Colors.CYAN}   Total = Frame + Max(Callees), Frame = Local variables, Depth = Call chain length{Colors.END}\n")
        
        # Table header with proper alignment
        print(f"{Colors.BOLD}{Colors.UNDERLINE}{'Flag':<5}{'Function Name':<40} {'Total':<7} {'Frame':<7} {'Depth':<5}{Colors.END}")
        print(f"{Colors.BOLD}{Colors.UNDERLINE}{'─────':<5}{'────────────────────────────────────────':<40} {'─────':<7} {'─────':<7} {'─────':<5}{Colors.END}")
        
        # Display function rows
        for func in filtered_functions:
            self._print_function_row(func, Colors.END)
        
        # Summary information
        very_low_cost = len([f for f in functions if f.cost < self.threshold and f.cost > 0])
        if very_low_cost > 0:
            print(f"\n{Colors.CYAN}💭 {very_low_cost} functions with very low cost (<{self.threshold} bytes) hidden for clarity{Colors.END}")
        
        print(f"\n{Colors.BOLD}📊 Displayed {len(filtered_functions)} of {len([f for f in functions if f.cost > 0])} functions with stack usage{Colors.END}")

    def _print_function_row(self, func: FunctionInfo, color: str) -> None:
        """
        Print a single function row in the analysis table.
        
        Uses consistent formatting with visual indicators for function types:
        - ▶ for root functions (entry points)
        - 🔄 for recursive functions
        - Color coding based on stack cost
        
        Args:
            func: Function information object
            color: Base color for the row
        """
        # Determine function type indicator with consistent spacing
        if func.is_recursive:
            flag = f"{Colors.RED}🔄{Colors.END}  "  # Recursive function
        elif func.is_root:
            flag = f"{Colors.GREEN}▶{Colors.END}   "  # Root function
        else:
            flag = "     "  # Regular function
        
        # Apply cost-based color coding
        cost_color = Colors.END
        if func.cost >= 500:
            cost_color = f"{Colors.RED}{Colors.BOLD}"
        elif func.cost >= 200:
            cost_color = f"{Colors.RED}"
        elif func.cost >= 100:
            cost_color = f"{Colors.YELLOW}"
        elif func.cost >= 50:
            cost_color = f"{Colors.CYAN}"
        else:
            cost_color = Colors.END
        
        # Handle long function names
        display_name = func.name
        if len(display_name) > 39:
            display_name = display_name[:36] + "..."
        
        # Print formatted row with consistent alignment
        print(f"{flag}{display_name:<40} {cost_color}{func.cost:<7}{Colors.END} {func.frame_size:<7} {func.height:<5}")

    def _print_summary(self, main_cost: int, max_iv_cost: int) -> None:
        """
        Display analysis summary with peak stack usage estimates.
        
        Provides estimates for:
        - Main execution path stack usage
        - Worst-case interrupt handler stack usage
        - Combined peak usage estimate
        - General statistics
        
        Args:
            main_cost: Stack cost of main function
            max_iv_cost: Maximum interrupt handler cost
        """
        print(f"\n{Colors.BOLD}{Colors.HEADER}📊 ANALYSIS SUMMARY{Colors.END}")
        print("─" * 50)
        
        interrupt_cost = self.total_cost.get("INTERRUPT", 0)
        total_peak = main_cost + max_iv_cost
        
        print(f"🎯 Peak execution estimate:")
        print(f"   Main function cost:     {Colors.CYAN}{main_cost:>6}{Colors.END} bytes")
        print(f"   Worst interrupt cost:   {Colors.YELLOW}{max_iv_cost:>6}{Colors.END} bytes")
        print(f"   Virtual interrupt node: {Colors.BLUE}{interrupt_cost:>6}{Colors.END} bytes")
        print(f"   {Colors.BOLD}Total estimated peak:   {Colors.GREEN}{total_peak:>6}{Colors.END}{Colors.BOLD} bytes{Colors.END}")
        
        # Additional statistics
        all_costs = list(self.total_cost.values())
        if all_costs:
            print(f"\n📈 Statistics:")
            print(f"   Functions analyzed:     {Colors.CYAN}{len(all_costs):>6}{Colors.END}")
            print(f"   Average stack usage:    {Colors.YELLOW}{sum(all_costs)//len(all_costs):>6}{Colors.END} bytes")
            print(f"   Maximum single function:{Colors.RED}{max(all_costs):>6}{Colors.END} bytes")

    def _print_unresolved(self) -> None:
        """
        Display list of unresolved function references.
        
        These are typically external library functions or system calls
        that don't have corresponding object files in the build directory.
        """
        if self.unresolved:
            print(f"\n{Colors.YELLOW}{Colors.BOLD}⚠️  UNRESOLVED FUNCTIONS{Colors.END}")
            print("─" * 30)
            print(f"{Colors.YELLOW}The following functions could not be resolved:{Colors.END}")
            
            # Display limited list to avoid overwhelming output
            sorted_unresolved = sorted(self.unresolved)
            for i, func in enumerate(sorted_unresolved):
                if i < 20:
                    print(f"   • {func}")
                elif i == 20:
                    print(f"   • ... and {len(sorted_unresolved) - 20} more")
                    break

def main():
    """
    Main entry point for the stack analyzer tool.
    
    Handles command line argument parsing, tool initialization,
    and orchestrates the complete analysis workflow.
    """
    parser = argparse.ArgumentParser(
        description="Analyze stack usage of ARM embedded firmware",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python3 stack_analyzer.py build
  python3 stack_analyzer.py cmake-build-debug
  python3 stack_analyzer.py build --threshold 50
  python3 stack_analyzer.py build --no-color
  python3 stack_analyzer.py build --no-warnings
        """
    )
    parser.add_argument('build_dir', help='Build directory containing object files')
    parser.add_argument('--threshold', type=int, default=10, 
                       help='Minimum stack usage threshold in bytes (default: 10)')
    parser.add_argument('--no-color', action='store_true', help='Disable colored output')
    parser.add_argument('--no-warnings', action='store_true', help='Suppress warning messages')
    parser.add_argument('--version', action='version', version=f'%(prog)s {__version__} by {__author__} ({__github__})')
    
    args = parser.parse_args()
    
    # Configure output formatting
    if args.no_color:
        for attr in dir(Colors):
            if not attr.startswith('_'):
                setattr(Colors, attr, '')
    
    # Display tool header
    print(f"{Colors.BOLD}{Colors.HEADER}🔍 ARM Stack Usage Analyzer{Colors.END}")
    print(f"{Colors.CYAN}Build directory: {args.build_dir}{Colors.END}")
    if args.threshold != 10:
        print(f"{Colors.CYAN}Threshold: {args.threshold} bytes{Colors.END}")
    if args.no_warnings:
        print(f"{Colors.CYAN}Warnings: disabled{Colors.END}")
    print()
    
    # Initialize and run analysis
    analyzer = StackAnalyzer(args.build_dir, args.threshold, not args.no_warnings)
    
    try:
        # Verification and setup phase
        obj_files = analyzer.check_prerequisites()
        
        print(f"\n{Colors.CYAN}Analyzing {len(obj_files)} object files...{Colors.END}")
        
        # Analysis workflow
        analyzer.parse_object_files(obj_files)
        analyzer.resolve_symbols()
        analyzer.create_interrupt_node()
        analyzer.trace_call_graph()
        analyzer.generate_report()
        
    except KeyboardInterrupt:
        print(f"\n{Colors.YELLOW}⚠️  Analysis interrupted by user{Colors.END}")
        sys.exit(1)
    except Exception as e:
        print(f"{Colors.RED}❌ Error during analysis: {e}{Colors.END}")
        sys.exit(1)

if __name__ == "__main__":
    main() 
